
help:  ## Show help
	@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	find . | grep -E "*.sh.e*" | xargs rm -rf
	find . | grep -E "*.save*" | xargs rm -rf
	rm -f .coverage

clean-logs: ## Clean logs
	rm -rf LOGS/**
	rm -rf notebooks/lightning_logs/**

hook: ## Run pre-commit hooks
	pre-commit run -a

push: ## Fast Push changes to the main branch
	git add .
	git commit -m "make push all"
	git push orgin main

pull: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

test: ## Run not slow tests
	pytest -k "not slow"

test-full: ## Run all tests
	pytest

train-debug: ## Train the model
	python ./train.py

eval-debug: ## Evaluate the model
	python ./evaluate_mp.py /data/milsrg1/huggingface/cache/efb48/diffsep/checkpoint.pt --split libri-clean

train: ## Train the model
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/continue_vae launch.sh

train_diffsep: ## Train the separation model
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/diffsep_train src/train_diffsep.sh

train_diffsep_latent: ## Train the separation model
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/out_latent_diffsep_train src/train_diffsep_latent.sh

finetune: ## Finetune the model
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/finetune finetune.sh
cont_train_vae:
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/cont_train src/cont_train_vae.sh
cont_train_score:
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/cont_train src/cont_train_score.sh
validate:
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/validate validate.sh
eval:
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/diffsep_eval_1000 scripts/eval_libri.sh

sleep: ## Sleep for 1 hour
	qsub -cwd -S /bin/bash -l qp=cuda-low,tests=0,mem_grab=0M,osrel="*",gpuclass="*", -o LOGS/diffsep_eval_1000 scripts/sleep.sh
unwrap: ## python ./unwrap_model.py --model-config stable_audio_tools/configs/model_configs/autoencoders/oobleck.json --ckpt-path vae_gan/k5tnlep2/checkpoints/epoch=63-step=1620000.ckpt --name vae_pretrained
	python ./unwrap_model.py --model-config stable_audio_tools/configs/model_configs/autoencoders/oobleck_finetune.json --ckpt-path vae_gan_finetune/vae_gan_finetune/bjpuomso/checkpoints/epoch=141-step=3600000.ckpt --name vae_finetuned
