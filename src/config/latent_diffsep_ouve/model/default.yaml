defaults:
    - _self_

n_speakers: 2
fs: 8000
t_eps: 0.03
t_rev_init: 0.03
ema_decay: 0.999
valid_max_sep_batches: 2
time_sampling_strategy: uniform
train_source_order: power
init_hack: 5
mmnr_thresh_pit: -10.0  # threshold for using pit with train_source_order=pit

score_model:
    _target_: models.diffsep.score_models.LatentScoreModelNCSNpp
    num_sources: ${model.n_speakers}
    backbone_args:
        _target_: models.diffsep.ncsnpp.NCSNpp
        nf: 128 # change to 128?
        image_size: 64
vae:
    config_path: "src/stable_audio_tools/configs/model_configs/autoencoders/oobleck_finetune.json"
    ckpt_path: "checkpoints/vae/vae_finetune.ckpt"
    trainable_vae: false
sde:
    _target_: sdes.sdes.OUVESDE
    ndim: ${model.n_speakers}
    theta: 1.5
    sigma_min: 0.05
    sigma_max: 0.5
    N: 30

sampler:
    N: 30
    snr: 0.5
    corrector_steps: 1

loss:
    _target_: torch.nn.MSELoss

main_val_loss: val/si_sdr
main_val_loss_mode: max
val_losses:
    val/si_sdr:
        _target_: models.diffsep.losses.SISDRLoss
        zero_mean: true
        clamp_db: 30
        reduction: mean
        sign_flip: true
    val/pesq:
        _target_: models.diffsep.losses.PESQ
        fs: ${model.fs}

optimizer:
    _target_: torch.optim.Adam
    lr: 0.00001
    weight_decay: 0.0
scheduler: null
grad_clipper:
    _target_: utils.FixedClipper
    max_norm: 5.0
