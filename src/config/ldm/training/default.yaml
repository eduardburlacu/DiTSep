defaults:
    - _self_

ema_decay: 0.999
valid_max_sep_batches: 2
time_sampling_strategy: uniform
train_source_order: pit
init_hack: 5
init_hack_p: 0.0
mmnr_thresh_pit: -10.0  # threshold for using pit with train_source_order=pit
use_ema: true
clip_grad_norm: 5.0

#discriminator:
#    _target_: stable_audio_tools.models.discriminators.EncodecDiscriminator
#    filters: 64
#    n_ffts: [2048, 1024, 512, 256, 128]
#    hop_lengths: [512, 256, 128, 64, 32]
#    win_lengths: [2048, 1024, 512, 256, 128]
#    in_channels: 2
#    out_channels: 2

#loss_config
loss:
    spectral:
        type: "mrstft"
        decay: 1.0
        weights: 
            mrstft: 1.0
        config:
            _target_: stable_audio_tools.training.losses.auraloss.MultiResolutionSTFTLoss
            sample_rate: ${model.fs}
            fft_sizes: [2048, 1024, 512, 256, 128, 64, 32]
            hop_sizes: [512, 256, 128, 64, 32, 16, 8]
            win_lengths: [2048, 1024, 512, 256, 128, 64, 32]
            perceptual_weighting: True

    #discriminator:
    #    type: "encodec"
    #    weights:
    #        adversarial: 0.1
    #        feature_matching: 5.0
    
    time:
        type: "l1"
        weights:
            l1: 15.0

main_val_loss: val/si_sdr
main_val_loss_mode: max

val_losses:
    val/si_sdr:
        _target_: models.diffsep.losses.SISDRLoss
        zero_mean: true
        clamp_db: 30
        reduction: mean
        sign_flip: true
        
    val/pesq:
        _target_: models.diffsep.losses.PESQ
        fs: ${model.fs}

    #val/stft:
    #    _target_: stable_audio_tools.training.losses.auraloss.STFTLoss
    #    sample_rate: ${model.fs}

    #val/mrstft:
    #    _target_: stable_audio_tools.training.losses.auraloss.MultiResolutionSTFTLoss
    #    sample_rate: ${model.fs}


optimizer:
    generator:
        type: AdamW
        config:
            lr: 0.00015 # 0.00015
            betas: [0.8, 0.99]
            weight_decay: 0.001
            amsgrad: true

    #discriminator:
    #    type: AdamW
    #    config:
    #        lr: 0.00030
    #        betas: [0.8, 0.99]
    #        weight_decay: 0.001
    #        amsgrad: true

    scheduler:
        type: InverseLR
        config:
            inv_gamma: 200000
            power: 0.5
            warmup: 0.999

ema:
    beta: 0.9999
    power: 0.75
    update_every: 1
    update_after_step: 1

scheduler: null

demo:
    demo_every: 2000
    sample_size: 247808